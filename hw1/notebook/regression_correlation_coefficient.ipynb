{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9FfatPz6MU3"
   },
   "source": [
    "# **Homework 1: Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7RiAkkjCc6l"
   },
   "source": [
    "# **Load 'train.csv'**\n",
    "train.csv 的資料為 12 個月中，每個月取 20 天，每天 24 小時的資料(每小時資料有 18 個 features)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "1AfNX-hB3kN8",
    "outputId": "6b9d36ea-d38a-4d74-8abe-61c32a038606"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./../data/train.csv', encoding = 'big5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqUdj00pDTpo"
   },
   "source": [
    "# **Preprocessing** \n",
    "取需要的數值部分，將 'RAINFALL' 欄位全部補 0。\n",
    "另外，如果要在 colab 重覆這段程式碼的執行，請從頭開始執行(把上面的都重新跑一次)，以避免跑出不是自己要的結果（若自己寫程式不會遇到，但 colab 重複跑這段會一直往下取資料。意即第一次取原本資料的第三欄之後的資料，第二次取第一次取的資料掉三欄之後的資料，...）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIGP7XUYD_Yb"
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:, 3:]\n",
    "data[data == 'NR'] = 0\n",
    "raw_data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7PCrVwX6jBF"
   },
   "source": [
    "# **Extract Features (1)**\n",
    "![圖片說明](https://drive.google.com/uc?id=1LyaqD4ojX07oe5oDzPO99l9ts5NRyArH)\n",
    "![圖片說明](https://drive.google.com/uc?id=1ZroBarcnlsr85gibeqEF-MtY13xJTG47)\n",
    "\n",
    "將原始 4320 * 18 的資料依照每個月分重組成 12 個 18 (features) * 480 (hours) 的資料。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBnrGYXu9dZQ"
   },
   "outputs": [],
   "source": [
    "month_data = {}\n",
    "for month in range(12):\n",
    "    sample = np.empty([18, 480])\n",
    "    for day in range(20):\n",
    "        sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
    "    month_data[month] = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.empty([18, 480*12])\n",
    "for i in range(18):\n",
    "    for m in range(12):\n",
    "        if m == 0:\n",
    "            temp = month_data[m][i,:]\n",
    "        else:\n",
    "            temp = np.concatenate((temp, month_data[m][i,:]), axis = -1)\n",
    "    items[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01712724,  0.25465706,  0.28311942,  0.29177826,  0.02997038,\n",
       "        0.44911349,  0.37556381,  0.35667002,  0.77642643,  1.        ,\n",
       "       -0.06265388, -0.26419607,  0.3708308 ,  0.3521594 ,  0.18613794,\n",
       "        0.15699025, -0.08470312, -0.04545785])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = np.corrcoef(items)[9]\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_bool = np.copy(cor)\n",
    "items_bool[items_bool > 0.3] = 1\n",
    "items_bool[items_bool <= 0.3] = 0\n",
    "items_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_month_data = {}\n",
    "for month in range(12):\n",
    "    j = 0\n",
    "    sample = np.empty([int(np.sum(items_bool)), 480])\n",
    "    for i in range(18):\n",
    "        if items_bool[i] == 1:\n",
    "            sample[j,:] = month_data[month][i,:]\n",
    "            j += 1\n",
    "    new_month_data[month] = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhVmtFEQ9D6t"
   },
   "source": [
    "# **Extract Features (2)**\n",
    "![alt text](https://drive.google.com/uc?id=1wKoPuaRHoX682LMiBgIoOP4PDyNKsJLK)\n",
    "![alt text](https://drive.google.com/uc?id=1FRWWiXQ-Qh0i9tyx0LiugHYF_xDdkhLN)\n",
    "\n",
    "每個月會有 480hrs，每 9 小時形成一個 data，每個月會有 471 個 data，故總資料數為 471 * 12 筆，而每筆 data 有 9 * 18 的 features (一小時 18 個 features * 9 小時)。\n",
    "\n",
    "對應的 target 則有 471 * 12 個(第 10 個小時的 PM2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "dcOrC4Fi-n3i",
    "outputId": "83541460-d78d-4214-f057-9c37c84593ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.   9.2  8.2 ...  1.9  1.9  2.1]\n",
      " [ 9.2  8.2  6.9 ...  1.9  2.1  2. ]\n",
      " [ 8.2  6.9  6.8 ...  2.1  2.   2. ]\n",
      " ...\n",
      " [ 6.4  5.7  6.1 ...  2.   1.9  1.9]\n",
      " [ 5.7  6.1  8.  ...  1.9  1.9  1.9]\n",
      " [ 6.1  8.  11.  ...  1.9  1.9  2. ]]\n",
      "[[30.]\n",
      " [41.]\n",
      " [44.]\n",
      " ...\n",
      " [17.]\n",
      " [24.]\n",
      " [29.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.empty([12 * 471, int(np.sum(items_bool)) * 9], dtype = float)\n",
    "y = np.empty([12 * 471, 1], dtype = float)\n",
    "for month in range(12):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):\n",
    "            if day == 19 and hour > 14:\n",
    "                continue\n",
    "            x[month * 471 + day * 24 + hour, :] = new_month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1, -1) #vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)\n",
    "            y[month * 471 + day * 24 + hour, 0] = month_data[month][9, day * 24 + hour + 9] #value\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wOii0TX8IwE"
   },
   "source": [
    "# **Normalize (1)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "ceMqFoNI8ftQ",
    "outputId": "99744546-62e0-4b92-db55-e570939eb2b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94869554, -0.14813488, -0.31066014, ...,  0.32976505,\n",
       "         0.33039252,  1.42801429],\n",
       "       [-0.14778078, -0.30935073, -0.52008895, ...,  0.32976505,\n",
       "         1.42627194,  0.87988955],\n",
       "       [-0.30902729, -0.51893132, -0.53619886, ...,  1.42549229,\n",
       "         0.87833223,  0.87988955],\n",
       "       ...,\n",
       "       [-0.59927103, -0.71239034, -0.64896822, ...,  0.87762867,\n",
       "         0.33039252,  0.33176481],\n",
       "       [-0.71214359, -0.647904  , -0.34287996, ...,  0.32976505,\n",
       "         0.33039252,  0.33176481],\n",
       "       [-0.64764498, -0.3415939 ,  0.14041729, ...,  0.32976505,\n",
       "         0.33039252,  0.87988955]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
    "std_x = np.std(x, axis = 0) #18 * 9 \n",
    "for i in range(len(x)): #12 * 471\n",
    "    for j in range(len(x[0])): #18 * 9 \n",
    "        if std_x[j] != 0:\n",
    "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzvXP5Jya64j"
   },
   "source": [
    "#**Split Training Data Into \"train_set\" and \"validation_set\"**\n",
    "這部分是針對作業中 report 的第二題、第三題做的簡單示範，以生成比較中用來訓練的 train_set 和不會被放入訓練、只是用來驗證的 validation_set。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "feF4XXOQb5SC",
    "outputId": "6fb8314b-7228-4c67-af30-c8496b27f184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94869554 -0.14813488 -0.31066014 ...  0.32976505  0.33039252\n",
      "   1.42801429]\n",
      " [-0.14778078 -0.30935073 -0.52008895 ...  0.32976505  1.42627194\n",
      "   0.87988955]\n",
      " [-0.30902729 -0.51893132 -0.53619886 ...  1.42549229  0.87833223\n",
      "   0.87988955]\n",
      " ...\n",
      " [-0.97013801 -0.56729608 -0.06901152 ... -0.7659622  -0.7654869\n",
      "  -0.21635992]\n",
      " [-0.56702172 -0.06752696  0.14041729 ... -0.7659622  -0.21754719\n",
      "  -0.21635992]\n",
      " [-0.06715752  0.14205364  0.94591271 ... -0.21809858 -0.21754719\n",
      "  -0.21635992]]\n",
      "[[30.]\n",
      " [41.]\n",
      " [44.]\n",
      " ...\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [14.]]\n",
      "[[ 0.14246295  0.94813285 -0.68118803 ... -0.21809858 -0.21754719\n",
      "  -0.21635992]\n",
      " [ 0.94869554 -0.68014717 -1.30947446 ... -0.21809858 -0.21754719\n",
      "  -0.76448466]\n",
      " [-0.67989428 -1.30888896 -1.27725464 ... -0.21809858 -0.7654869\n",
      "  -0.76448466]\n",
      " ...\n",
      " [-0.59927103 -0.71239034 -0.64896822 ...  0.87762867  0.33039252\n",
      "   0.33176481]\n",
      " [-0.71214359 -0.647904   -0.34287996 ...  0.32976505  0.33039252\n",
      "   0.33176481]\n",
      " [-0.64764498 -0.3415939   0.14041729 ...  0.32976505  0.33039252\n",
      "   0.87988955]]\n",
      "[[13.]\n",
      " [24.]\n",
      " [22.]\n",
      " ...\n",
      " [17.]\n",
      " [24.]\n",
      " [29.]]\n",
      "4521\n",
      "4521\n",
      "1131\n",
      "1131\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "x_train_set = x[: math.floor(len(x) * 0.8), :]\n",
    "y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
    "x_validation = x[math.floor(len(x) * 0.8): , :]\n",
    "y_validation = y[math.floor(len(y) * 0.8): , :]\n",
    "print(x_train_set)\n",
    "print(y_train_set)\n",
    "print(x_validation)\n",
    "print(y_validation)\n",
    "print(len(x_train_set))\n",
    "print(len(y_train_set))\n",
    "print(len(x_validation))\n",
    "print(len(y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-qAu0KR_ZRR"
   },
   "source": [
    "# **Training**\n",
    "![alt text](https://drive.google.com/uc?id=1xIXvqZ4EGgmxrp7c9r0LOVbcvd4d9H4N)\n",
    "![alt text](https://drive.google.com/uc?id=1S42g06ON5oJlV2f9RukxawjbE4NpsaB6)\n",
    "![alt text](https://drive.google.com/uc?id=1BbXu-oPB9EZBHDQ12YCkYqtyAIil3bGj)\n",
    "\n",
    "(和上圖不同處: 下面的 code 採用 Root Mean Square Error)\n",
    "\n",
    "因為常數項的存在，所以 dimension (dim) 需要多加一欄；eps 項是避免 adagrad 的分母為 0 而加的極小數值。\n",
    "\n",
    "每一個 dimension (dim) 會對應到各自的 gradient, weight (w)，透過一次次的 iteration (iter_time) 學習。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cCzDfxBFBFqp",
    "outputId": "2e2eef7e-a49a-48bd-db5e-36e554c20105",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "w = np.zeros([dim, 1])\n",
    "x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "learning_rate = 1.5\n",
    "iter_time = 20000\n",
    "adagrad = np.zeros([dim, 1])\n",
    "eps = 0.0000000001\n",
    "for t in range(iter_time):\n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2))/471/12)#rmse\n",
    "    if(t%100==0):\n",
    "        print(str(t) + \":\" + str(loss))\n",
    "    gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y) #dim*1\n",
    "    adagrad += gradient ** 2\n",
    "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "# np.save('./../model/weight.npy', w)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqNdWKsYBK28"
   },
   "source": [
    "# **Testing**\n",
    "![alt text](https://drive.google.com/uc?id=1165ETzZyE6HStqKvgR0gKrJwgFLK6-CW)\n",
    "\n",
    "載入 test data，並且以相似於訓練資料預先處理和特徵萃取的方式處理，使 test data 形成 240 個維度為 18 * 9 + 1 的資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "AALygqJFCWOA",
    "outputId": "1a840905-645a-400e-c92b-d97fce8a3fad"
   },
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('./../data/test.csv', header = None, encoding = 'big5')\n",
    "test_data = testdata.iloc[:, 2:]\n",
    "test_data[test_data == 'NR'] = 0\n",
    "test_data = test_data.to_numpy()\n",
    "test_x = np.empty([240, int(np.sum(items_bool)*9)], dtype = float)\n",
    "k = 0\n",
    "for i in range(18):\n",
    "    if items_bool[i] == 1:\n",
    "        for j in range(240):\n",
    "                test_x[j, k*9 : (k+1)*9] = test_data[18 * j + i, :]\n",
    "        k += 1\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1).astype(float)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJQks9JEHR6W"
   },
   "source": [
    "# **Prediction**\n",
    "說明圖同上\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1165ETzZyE6HStqKvgR0gKrJwgFLK6-CW)\n",
    "\n",
    "有了 weight 和測試資料即可預測 target。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jNyB229jHsEQ",
    "outputId": "b2ef6cbb-e040-4b03-9c0f-25eb91665cd1"
   },
   "outputs": [],
   "source": [
    "# w = np.load('./../model/weight.npy')\n",
    "ans_y = np.dot(test_x, w)\n",
    "ans_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKMKW7RzHwuO"
   },
   "source": [
    "# **Save Prediction to CSV File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Dwfpqqy0H8en",
    "outputId": "38e75a01-b540-4d64-bbbd-3139456128e6"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./../results/submit.csv', mode='w', newline='') as submit_file:\n",
    "    csv_writer = csv.writer(submit_file)\n",
    "    header = ['id', 'value']\n",
    "    print(header)\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(240):\n",
    "        row = ['id_' + str(i), ans_y[i][0]]\n",
    "        csv_writer.writerow(row)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Homework1 report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1\n",
    "\n",
    "### 使用四種不同的 learning rate 進行 training (其他參數需一致)，作圖並討論其收斂過程（橫軸為 iteration 次數，縱軸為 loss 的大小，四種 learning rate 的收斂線請以不同顏色呈現在一張圖裡做比較）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.empty([12 * 471, int(np.sum(items_bool)) * 9], dtype = float)\n",
    "y = np.empty([12 * 471, 1], dtype = float)\n",
    "for month in range(12):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):\n",
    "            if day == 19 and hour > 14:\n",
    "                continue\n",
    "            x[month * 471 + day * 24 + hour, :] = new_month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1, -1) #vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)\n",
    "            y[month * 471 + day * 24 + hour, 0] = month_data[month][9, day * 24 + hour + 9] #value\n",
    "# Normalize\n",
    "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
    "std_x = np.std(x, axis = 0) #18 * 9 \n",
    "for i in range(len(x)): #12 * 471\n",
    "    for j in range(len(x[0])): #18 * 9 \n",
    "        if std_x[j] != 0:\n",
    "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate_list = [10**power for power in range(-1,3)]\n",
    "loss_history = []\n",
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "iter_time = 1000\n",
    "eps = 0.0000000001\n",
    "for lr in learning_rate_list:\n",
    "    print(\"Use learning rate:\", lr)\n",
    "    history = []\n",
    "    w = np.zeros([dim, 1])\n",
    "    temp_x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "    learning_rate = lr\n",
    "    adagrad = np.zeros([dim, 1])\n",
    "    for t in range(iter_time):\n",
    "        loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y, 2))/471/12)#rmse\n",
    "        history.append(loss)\n",
    "        if(t%100==0):\n",
    "            print(str(t) + \":\" + str(loss))\n",
    "        gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y) #dim*1\n",
    "        adagrad += gradient ** 2\n",
    "        w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    loss_history.append(history)\n",
    "loss_history = np.array(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loss_history.shape[0]):\n",
    "    plt.plot(\n",
    "        np.arange(loss_history.shape[1])+1,\n",
    "        np.log10(loss_history[i,:]),\n",
    "        label = 'learning rate: ' + str(learning_rate_list[i])\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title('loss $(log_{10})$')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will find that the best learning rate $\\eta$ should be between 10 and 100\n",
    "### Let's try to tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate_list = np.arange(10,110,10)\n",
    "loss_history = []\n",
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "iter_time = 1000\n",
    "eps = 0.0000000001\n",
    "for lr in learning_rate_list:\n",
    "    print(\"Use learning rate:\", lr)\n",
    "    history = []\n",
    "    w = np.zeros([dim, 1])\n",
    "    temp_x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "    learning_rate = lr\n",
    "    adagrad = np.zeros([dim, 1])\n",
    "    for t in range(iter_time):\n",
    "        loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y, 2))/471/12)#rmse\n",
    "        history.append(loss)\n",
    "        if(t%100==0):\n",
    "            print(str(t) + \":\" + str(loss))\n",
    "        gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y) #dim*1\n",
    "        adagrad += gradient ** 2\n",
    "        w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    loss_history.append(history)\n",
    "loss_history = np.array(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loss_history.shape[0]):\n",
    "    plt.plot(\n",
    "        (np.arange(loss_history.shape[1])+1)[750:],\n",
    "        (np.log10(loss_history[i,:]))[750:],\n",
    "        label = 'learning rate: ' + str(learning_rate_list[i])\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title('loss $(log_{10})$')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate_list = np.arange(5,16,1)\n",
    "loss_history = []\n",
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "iter_time = 1000\n",
    "eps = 0.0000000001\n",
    "for lr in learning_rate_list:\n",
    "    print(\"Use learning rate:\", lr)\n",
    "    history = []\n",
    "    w = np.zeros([dim, 1])\n",
    "    temp_x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "    learning_rate = lr\n",
    "    adagrad = np.zeros([dim, 1])\n",
    "    for t in range(iter_time):\n",
    "        loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y, 2))/471/12)#rmse\n",
    "        history.append(loss)\n",
    "        if(t%100==0):\n",
    "            print(str(t) + \":\" + str(loss))\n",
    "        gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y) #dim*1\n",
    "        adagrad += gradient ** 2\n",
    "        w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    loss_history.append(history)\n",
    "loss_history = np.array(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loss_history.shape[0]):\n",
    "    plt.plot(\n",
    "        (np.arange(loss_history.shape[1])+1)[1750:],\n",
    "        (np.log10(loss_history[i,:]))[1750:],\n",
    "        label = 'learning rate: ' + str(learning_rate_list[i])\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title('loss $(log_{10})$')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history[:,-1], loss_history[-4,-1], learning_rate_list[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate_list = np.arange(1,5.5,0.5)\n",
    "loss_history = []\n",
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "iter_time = 2000\n",
    "eps = 0.0000000001\n",
    "for lr in learning_rate_list:\n",
    "    print(\"Use learning rate:\", lr)\n",
    "    history = []\n",
    "    w = np.zeros([dim, 1])\n",
    "    temp_x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "    learning_rate = lr\n",
    "    adagrad = np.zeros([dim, 1])\n",
    "    for t in range(iter_time):\n",
    "        loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y, 2))/471/12)#rmse\n",
    "        history.append(loss)\n",
    "        if(t%100==0):\n",
    "            print(str(t) + \":\" + str(loss))\n",
    "        gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y) #dim*1\n",
    "        adagrad += gradient ** 2\n",
    "        w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    loss_history.append(history)\n",
    "loss_history = np.array(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loss_history.shape[0]):\n",
    "    plt.plot(\n",
    "        (np.arange(loss_history.shape[1])+1)[1900:],\n",
    "        (np.log10(loss_history[i,:]))[1900:],\n",
    "        label = 'learning rate: ' + str(learning_rate_list[i])\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title('loss $(log_{10})$')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history[:,-1]\n",
    "# , loss_history[-4,-1], learning_rate_list[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim = int(np.sum(items_bool) * 9 + 1)\n",
    "w = np.zeros([dim, 1])\n",
    "temp_x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "learning_rate = 1\n",
    "iter_time = 20000\n",
    "adagrad = np.zeros([dim, 1])\n",
    "eps = 0.0000000001\n",
    "for t in range(iter_time):\n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(temp_x, w) - y, 2))/471/12)#rmse\n",
    "    if(t%100==0):\n",
    "        print(str(t) + \":\" + str(loss))\n",
    "    gradient = 2 * np.dot(temp_x.transpose(), np.dot(temp_x, w) - y) #dim*1\n",
    "    adagrad += gradient ** 2\n",
    "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "np.save('./../model/weight3.npy', w)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.load('./../model/weight3.npy')\n",
    "ans_y = np.dot(test_x, w)\n",
    "ans_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./../results/submit3.csv', mode='w', newline='') as submit_file:\n",
    "    csv_writer = csv.writer(submit_file)\n",
    "    header = ['id', 'value']\n",
    "    print(header)\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(240):\n",
    "        row = ['id_' + str(i), ans_y[i][0]]\n",
    "        csv_writer.writerow(row)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
